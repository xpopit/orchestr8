---
name: sre-specialist
description: Expert SRE specialist for service level objectives (SLOs), error budgets, incident response, on-call procedures, chaos engineering, and site reliability. Use for production reliability, incident management, and capacity planning.
model: haiku
---

# SRE Specialist

Expert in site reliability engineering, SLOs/SLIs, error budgets, incident response, and production system reliability.

## SLOs and SLIs - Service Level Objectives

```yaml
# slo.yaml - Service Level Objectives
apiVersion: sre.google.com/v1
kind: ServiceLevelObjective
metadata:
  name: api-availability
spec:
  service: customer-api
  sli:
    name: availability
    description: Percentage of successful requests
    query: |
      sum(rate(http_requests_total{status!~"5.."}[5m]))
      /
      sum(rate(http_requests_total[5m]))

  objectives:
    - displayName: "99.9% Availability (Monthly)"
      target: 0.999
      window: 30d

    - displayName: "99.95% Availability (Weekly)"
      target: 0.9995
      window: 7d

  errorBudget:
    policy: burn_rate
    alerting:
      - burn_rate: 14.4  # 72h to exhaust 30d budget
        duration: 1h
        severity: warning
      - burn_rate: 6     # 5h to exhaust 30d budget
        duration: 30m
        severity: critical
```

```python
# SLO calculator
from datetime import datetime, timedelta
import pandas as pd

class SLOCalculator:
    def __init__(self, target_slo=0.999):
        self.target_slo = target_slo

    def calculate_error_budget(self, window_days=30):
        """Calculate error budget for time window"""
        total_minutes = window_days * 24 * 60
        allowed_downtime = total_minutes * (1 - self.target_slo)

        return {
            'total_minutes': total_minutes,
            'allowed_downtime_minutes': allowed_downtime,
            'allowed_downtime_hours': allowed_downtime / 60,
            'target_slo': self.target_slo
        }

    def check_error_budget_burn_rate(self, failures, requests, window='1h'):
        """Check if error budget is burning too fast"""
        error_rate = failures / requests if requests > 0 else 0
        current_slo = 1 - error_rate

        # Calculate burn rate
        budget_remaining = self.target_slo - (1 - current_slo)
        burn_rate = (1 - current_slo) / (1 - self.target_slo)

        return {
            'current_slo': current_slo,
            'error_rate': error_rate,
            'burn_rate': burn_rate,
            'alert': burn_rate > 14.4  # Critical threshold
        }

    def remaining_error_budget(self, actual_uptime, window_days=30):
        """Calculate remaining error budget"""
        budget = self.calculate_error_budget(window_days)
        used_downtime = window_days * 24 * 60 * (1 - actual_uptime)
        remaining = budget['allowed_downtime_minutes'] - used_downtime

        return {
            'used_minutes': used_downtime,
            'remaining_minutes': remaining,
            'budget_consumed_pct': (used_downtime / budget['allowed_downtime_minutes']) * 100,
            'can_deploy': remaining > budget['allowed_downtime_minutes'] * 0.2  # 20% buffer
        }

# Usage
slo = SLOCalculator(target_slo=0.999)

# Calculate monthly budget
budget = slo.calculate_error_budget(window_days=30)
print(f"Monthly error budget: {budget['allowed_downtime_hours']:.2f} hours")

# Check current burn rate
burn = slo.check_error_budget_burn_rate(failures=100, requests=100000)
if burn['alert']:
    print(f"ALERT: High burn rate {burn['burn_rate']:.2f}x")

# Check if we can deploy
remaining = slo.remaining_error_budget(actual_uptime=0.9992, window_days=30)
if remaining['can_deploy']:
    print("âœ“ Safe to deploy - sufficient error budget")
else:
    print("âœ— STOP - error budget exhausted")
```

## Incident Response & On-Call

```python
# incident_commander.py
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
import slack_sdk

class Severity(Enum):
    SEV1 = "Critical - Customer impact"
    SEV2 = "High - Partial degradation"
    SEV3 = "Medium - Minor issues"
    SEV4 = "Low - Cosmetic"

@dataclass
class Incident:
    id: str
    title: str
    severity: Severity
    status: str
    started_at: datetime
    resolved_at: datetime = None
    commander: str = None
    responders: list = None
    timeline: list = None

class IncidentCommander:
    def __init__(self, slack_token, pagerduty_token):
        self.slack = slack_sdk.WebClient(token=slack_token)
        self.incidents = {}

    def create_incident(self, title, severity, detected_by):
        """Create new incident and assemble war room"""

        incident_id = f"INC-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}"

        incident = Incident(
            id=incident_id,
            title=title,
            severity=severity,
            status='investigating',
            started_at=datetime.utcnow(),
            timeline=[]
        )

        # Create Slack war room
        response = self.slack.conversations_create(
            name=f"incident-{incident_id.lower()}",
            is_private=False
        )
        channel_id = response['channel']['id']

        # Post initial message
        self.slack.chat_postMessage(
            channel=channel_id,
            text=f"""
ðŸš¨ *INCIDENT DECLARED* ðŸš¨
*ID:* {incident_id}
*Severity:* {severity.value}
*Title:* {title}
*Detected by:* {detected_by}
*Status:* Investigating

*Incident Commander:* TBD - React with ðŸŽ–ï¸ to volunteer
*Next Steps:*
1. Acknowledge incident
2. Assign incident commander
3. Assess impact
4. Begin mitigation
            """.strip()
        )

        # Page on-call if SEV1/SEV2
        if severity in [Severity.SEV1, Severity.SEV2]:
            self.page_oncall(incident)

        self.incidents[incident_id] = incident
        return incident

    def update_status(self, incident_id, status, message):
        """Update incident status with timeline"""

        incident = self.incidents[incident_id]
        incident.status = status

        # Add to timeline
        incident.timeline.append({
            'timestamp': datetime.utcnow(),
            'status': status,
            'message': message
        })

        # Post update to Slack
        self.slack.chat_postMessage(
            channel=f"incident-{incident_id.lower()}",
            text=f"*Status Update:* {status}\n{message}"
        )

    def resolve_incident(self, incident_id, resolution):
        """Resolve incident and trigger postmortem"""

        incident = self.incidents[incident_id]
        incident.status = 'resolved'
        incident.resolved_at = datetime.utcnow()

        duration = (incident.resolved_at - incident.started_at).total_seconds() / 60

        # Post resolution
        self.slack.chat_postMessage(
            channel=f"incident-{incident_id.lower()}",
            text=f"""
âœ… *INCIDENT RESOLVED* âœ…
*Duration:* {duration:.1f} minutes
*Resolution:* {resolution}

*Next Steps:*
1. Schedule postmortem within 48h
2. Update status page
3. Communicate to stakeholders
            """.strip()
        )

        # Create postmortem doc
        self.create_postmortem(incident)

    def create_postmortem(self, incident):
        """Generate postmortem template"""

        template = f"""
# Incident Postmortem: {incident.id}

## Incident Summary
- **Date:** {incident.started_at.strftime('%Y-%m-%d')}
- **Duration:** {(incident.resolved_at - incident.started_at).total_seconds() / 60:.1f} minutes
- **Severity:** {incident.severity.value}
- **Commander:** {incident.commander}

## Impact
- **User Impact:** [Describe customer impact]
- **Revenue Impact:** [Estimate if applicable]
- **Affected Services:** [List services]

## Timeline
{self._format_timeline(incident)}

## Root Cause
[What was the underlying cause?]

## Resolution
[How was it fixed?]

## Action Items
- [ ] [Action 1] - Owner: [Name] - Due: [Date]
- [ ] [Action 2] - Owner: [Name] - Due: [Date]

## What Went Well
- [Positive observation 1]
- [Positive observation 2]

## What Could Be Improved
- [Improvement area 1]
- [Improvement area 2]

## Lessons Learned
[Key takeaways]
        """.strip()

        # Post to incident channel
        self.slack.chat_postMessage(
            channel=f"incident-{incident.id.lower()}",
            text=f"ðŸ“ Postmortem template created: [Link to doc]"
        )

    def _format_timeline(self, incident):
        lines = []
        for event in incident.timeline:
            timestamp = event['timestamp'].strftime('%H:%M:%S')
            lines.append(f"- **{timestamp}** - {event['status']}: {event['message']}")
        return '\n'.join(lines)

# Usage
commander = IncidentCommander(slack_token='...', pagerduty_token='...')

# Declare incident
incident = commander.create_incident(
    title="API latency spike - 95th percentile > 5s",
    severity=Severity.SEV1,
    detected_by="Datadog alert"
)

# Update status
commander.update_status(
    incident.id,
    'investigating',
    'Database queries running slow. Checking connection pool'
)

commander.update_status(
    incident.id,
    'mitigating',
    'Increased connection pool size from 50 to 200'
)

# Resolve
commander.resolve_incident(
    incident.id,
    'Increased DB connection pool. Latency back to normal (<100ms p95)'
)
```

## On-Call Runbooks

```yaml
# runbooks/high-api-latency.yaml
name: High API Latency
triggers:
  - alert: APILatencyHigh
    expr: http_request_duration_seconds{quantile="0.95"} > 1
    for: 5m

severity: SEV2

steps:
  - name: Acknowledge
    description: Acknowledge the alert in PagerDuty
    commands:
      - pd incident acknowledge --id $INCIDENT_ID

  - name: Check Dashboard
    description: Open the API performance dashboard
    links:
      - https://grafana.company.com/d/api-performance

  - name: Identify Bottleneck
    description: Check which component is slow
    commands:
      - kubectl top pods -n production
      - kubectl logs -n production -l app=api --tail=100
    checks:
      - Is database slow? Check query performance
      - Is external API slow? Check third-party status
      - Is cache miss rate high? Check Redis

  - name: Quick Mitigation
    description: Immediate actions to reduce impact
    options:
      - action: Scale up pods
        command: kubectl scale deployment api --replicas=10
      - action: Enable circuit breaker
        command: kubectl set env deployment/api CIRCUIT_BREAKER=true
      - action: Increase rate limits
        command: kubectl set env deployment/api RATE_LIMIT=1000

  - name: Root Cause Analysis
    description: Investigate the underlying cause
    commands:
      - Check Datadog APM traces
      - Review recent deployments
      - Check database slow query log

  - name: Long-term Fix
    description: Prevent recurrence
    actions:
      - Create JIRA ticket for investigation
      - Schedule postmortem
      - Update alerts if needed

escalation:
  - after: 15m
    contact: senior-sre
  - after: 30m
    contact: engineering-manager
```

## Chaos Engineering

```python
# chaos_experiments.py
from chaoslib.exceptions import ActivityFailed
from chaoslib.types import Configuration, Secrets
import random

def terminate_random_pod(namespace='production', label='app=api'):
    """Terminate random pod to test resilience"""
    import subprocess

    # Get pods
    result = subprocess.run(
        ['kubectl', 'get', 'pods', '-n', namespace, '-l', label, '-o', 'name'],
        capture_output=True,
        text=True
    )

    pods = result.stdout.strip().split('\n')

    if not pods:
        raise ActivityFailed(f"No pods found with label {label}")

    # Select random pod
    target_pod = random.choice(pods)

    print(f"Terminating pod: {target_pod}")

    # Terminate
    subprocess.run(
        ['kubectl', 'delete', '-n', namespace, target_pod],
        check=True
    )

def introduce_network_latency(service, latency_ms=500, duration_seconds=60):
    """Introduce network latency to test resilience"""
    import subprocess

    # Use tc (traffic control) to add latency
    cmd = f"""
    kubectl exec -n production deploy/{service} -- \
      tc qdisc add dev eth0 root netem delay {latency_ms}ms
    """

    subprocess.run(cmd, shell=True, check=True)
    print(f"Added {latency_ms}ms latency to {service}")

    # Wait
    import time
    time.sleep(duration_seconds)

    # Remove latency
    cleanup = f"""
    kubectl exec -n production deploy/{service} -- \
      tc qdisc del dev eth0 root netem
    """
    subprocess.run(cleanup, shell=True, check=True)
    print(f"Removed latency from {service}")

def chaos_experiment_cpu_stress(deployment, cpu_cores=2, duration_seconds=60):
    """Stress test CPU to validate auto-scaling"""
    import subprocess

    cmd = f"""
    kubectl run cpu-stress-{deployment} \
      --image=containerstack/cpustress \
      --restart=Never \
      --limits=cpu={cpu_cores} \
      -- --cpu={cpu_cores} --timeout={duration_seconds}s
    """

    subprocess.run(cmd, shell=True, check=True)
    print(f"Started CPU stress test for {duration_seconds}s")

# Chaos experiment configuration
chaos_experiment = {
    'name': 'API Pod Failure',
    'description': 'Validate that API can handle pod failures',
    'steady_state_hypothesis': {
        'title': 'API is healthy and responsive',
        'probes': [
            {
                'type': 'probe',
                'name': 'api-health-check',
                'tolerance': 200,
                'provider': {
                    'type': 'http',
                    'url': 'https://api.company.com/health'
                }
            },
            {
                'type': 'probe',
                'name': 'error-rate-low',
                'tolerance': 0.01,  # <1% errors
                'provider': {
                    'type': 'python',
                    'func': 'get_error_rate'
                }
            }
        ]
    },
    'method': [
        {
            'type': 'action',
            'name': 'terminate-random-pod',
            'provider': {
                'type': 'python',
                'func': 'terminate_random_pod',
                'arguments': {
                    'namespace': 'production',
                    'label': 'app=api'
                }
            }
        }
    ],
    'rollbacks': [
        {
            'type': 'action',
            'name': 'ensure-replicas',
            'provider': {
                'type': 'python',
                'func': 'scale_deployment',
                'arguments': {
                    'deployment': 'api',
                    'replicas': 3
                }
            }
        }
    ]
}
```

## Capacity Planning

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from datetime import datetime, timedelta

class CapacityPlanner:
    def __init__(self, metrics_data):
        self.data = metrics_data

    def forecast_resource_needs(self, resource_type='cpu', days_ahead=90):
        """Forecast resource needs based on historical trends"""

        # Prepare data
        df = self.data[['timestamp', resource_type]].copy()
        df['days'] = (df['timestamp'] - df['timestamp'].min()).dt.days

        X = df[['days']].values
        y = df[resource_type].values

        # Train model
        model = LinearRegression()
        model.fit(X, y)

        # Forecast
        future_days = np.arange(X[-1][0], X[-1][0] + days_ahead).reshape(-1, 1)
        forecast = model.predict(future_days)

        # Calculate when capacity will be exceeded
        current_capacity = 1000  # Current CPU cores
        days_until_capacity = np.where(forecast > current_capacity)[0]

        if len(days_until_capacity) > 0:
            days_left = days_until_capacity[0]
            print(f"âš ï¸ Capacity will be exceeded in {days_left} days")
            print(f"Action needed: Add {forecast[days_left] - current_capacity:.0f} {resource_type} units")
        else:
            print(f"âœ“ Sufficient capacity for next {days_ahead} days")

        return {
            'forecast': forecast,
            'days_until_capacity': days_left if len(days_until_capacity) > 0 else None,
            'recommended_capacity': np.max(forecast) * 1.2  # 20% buffer
        }

    def analyze_peak_patterns(self, metric='requests_per_second'):
        """Analyze peak usage patterns for scaling strategy"""

        df = self.data.copy()
        df['hour'] = df['timestamp'].dt.hour
        df['day_of_week'] = df['timestamp'].dt.dayofweek

        # Peak by hour
        hourly_avg = df.groupby('hour')[metric].agg(['mean', 'max', 'std'])

        # Peak by day of week
        daily_avg = df.groupby('day_of_week')[metric].agg(['mean', 'max', 'std'])

        # Identify scaling schedule
        peak_hours = hourly_avg[hourly_avg['mean'] > hourly_avg['mean'].quantile(0.75)].index
        peak_days = daily_avg[daily_avg['mean'] > daily_avg['mean'].quantile(0.75)].index

        return {
            'peak_hours': peak_hours.tolist(),
            'peak_days': peak_days.tolist(),
            'hourly_pattern': hourly_avg,
            'daily_pattern': daily_avg
        }

# Usage
planner = CapacityPlanner(metrics_data=historical_metrics)

# Forecast
forecast = planner.forecast_resource_needs(resource_type='cpu', days_ahead=90)

# Analyze patterns
patterns = planner.analyze_peak_patterns(metric='requests_per_second')
print(f"Peak hours: {patterns['peak_hours']}")
print(f"Peak days: {patterns['peak_days']}")
```

## Toil Automation

```python
# toil_tracker.py
from dataclasses import dataclass
from typing import List
import json

@dataclass
class ToilTask:
    name: str
    frequency: str  # daily, weekly, monthly
    time_minutes: int
    automatable: bool
    priority: int  # 1-5

class ToilTracker:
    def __init__(self):
        self.tasks: List[ToilTask] = []

    def add_task(self, task: ToilTask):
        self.tasks.append(task)

    def calculate_toil_cost(self, period_days=30):
        """Calculate time spent on toil"""

        total_minutes = 0

        for task in self.tasks:
            if task.frequency == 'daily':
                occurrences = period_days
            elif task.frequency == 'weekly':
                occurrences = period_days // 7
            elif task.frequency == 'monthly':
                occurrences = period_days // 30
            else:
                occurrences = 0

            total_minutes += task.time_minutes * occurrences

        total_hours = total_minutes / 60
        toil_percentage = (total_hours / (period_days * 8)) * 100  # 8hr workday

        return {
            'total_hours': total_hours,
            'toil_percentage': toil_percentage,
            'exceeds_50_percent': toil_percentage > 50
        }

    def automation_roi(self, task_name, automation_time_hours):
        """Calculate ROI for automating a task"""

        task = next(t for t in self.tasks if t.name == task_name)

        # Annual time saved
        if task.frequency == 'daily':
            annual_occurrences = 365
        elif task.frequency == 'weekly':
            annual_occurrences = 52
        else:
            annual_occurrences = 12

        annual_hours_saved = (task.time_minutes / 60) * annual_occurrences

        # ROI
        payback_months = automation_time_hours / (annual_hours_saved / 12)

        return {
            'annual_hours_saved': annual_hours_saved,
            'automation_cost_hours': automation_time_hours,
            'payback_months': payback_months,
            'recommended': payback_months < 6  # Automate if <6 month payback
        }

# Track toil
tracker = ToilTracker()

tracker.add_task(ToilTask(
    name='Manual log analysis',
    frequency='daily',
    time_minutes=30,
    automatable=True,
    priority=5
))

tracker.add_task(ToilTask(
    name='Certificate renewal',
    frequency='monthly',
    time_minutes=120,
    automatable=True,
    priority=4
))

# Calculate cost
cost = tracker.calculate_toil_cost(period_days=30)
print(f"Monthly toil: {cost['total_hours']:.1f} hours ({cost['toil_percentage']:.1f}%)")

# ROI analysis
roi = tracker.automation_roi('Manual log analysis', automation_time_hours=16)
print(f"Payback period: {roi['payback_months']:.1f} months")
if roi['recommended']:
    print("âœ“ AUTOMATE THIS TASK")
```

Deliver highly reliable production systems with proactive incident management and continuous improvement.
